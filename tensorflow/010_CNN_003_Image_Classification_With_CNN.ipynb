{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6ea499-88a6-4a6b-b2d5-d89b17b5c7bf",
   "metadata": {},
   "source": [
    "# CNN 3 - Getting started with Convolutional layers\n",
    "- Dataset:\n",
    "    - https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset\n",
    "- The dataset isn't deep-learning-compatible by default, here's how to preprocess it:\n",
    "    - Video: https://www.youtube.com/watch?v=O7EV2BjOXus&ab_channel=BetterDataScience\n",
    "    - Article:https://towardsdatascience.com/tensorflow-for-image-classification-top-3-prerequisites-for-deep-learning-projects-34c549c89e42\n",
    "    - Code: https://github.com/fenago/deeplearning/blob/main/tensorflow/008_CNN_001_Working_With_Image_Data.ipynb\n",
    "    \n",
    "**Before you start**\n",
    "- I got TensorFlow errors during training because a couple of images were corrupted\n",
    "- Before continuing, please delete the following images:\n",
    "    - `data\\train\\cat\\666.jpg`\n",
    "    - `data\\train\\dog\\11702.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b9afd-77b2-4b2b-a753-95770a7b7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1a334-7eaa-4c2f-85aa-e800a7922fac",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Normalizing image data\n",
    "- Let's load in a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b5178-3dd3-47af-bdd0-e6bde97f4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open('data/train/cat/1.jpg')\n",
    "display(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081123d0-e47a-49ff-ab39-ace236aa1a78",
   "metadata": {},
   "source": [
    "- And check it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0f84f-82d5-4a39-9e99-bd1f568d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f62c6e-aa3b-411a-9efe-72b1e4b0cedc",
   "metadata": {},
   "source": [
    "- It's 281 pixels wide, 300 pixels tall, and has 3 color channels\n",
    "- Let's load in another image and see if the same applies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89580d1b-21c2-4af4-845f-8fb1f64acdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = Image.open('data/train/dog/0.jpg')\n",
    "display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdda40-bf9a-4235-9f59-a13cd609a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eae4a1-81d6-48e5-96d2-1994837617c3",
   "metadata": {},
   "source": [
    "- The second image is much larger\n",
    "- Neural network doesn't like that - it expects images (arrays) of identical sizes\n",
    "- You'll see later how to resize them on the fly\n",
    "- First, let's see how a single image looks like when represented as an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0b9f4-2a42-4550-8588-4a926830594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c8b98-0b95-4074-91b3-d73dad1282fb",
   "metadata": {},
   "source": [
    "- It's in a range between 0 and 255 for every single color channel (red, green, and blue)\n",
    "- Neural networks prefer a range between 0 and 1\n",
    "- We can translate it to that range by dividing each element of an array by 255.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee85e2-512b-4aa2-afa4-d174891aa7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736c4bd-4f58-437a-a02e-071b2b416c72",
   "metadata": {},
   "source": [
    "- That's the only argument we'll pass to the TensorFlow's ImageDataGenerator - rescaling\n",
    "- There are others available, and we'll cover them in a couple of notebooks when learning data augmentation\n",
    "\n",
    "<br>\n",
    "\n",
    "## Data loaders\n",
    "- You can use the `ImageDataGenerator` class from TensorFlow to specify how the image data will be generated\n",
    "- We'll only apply rescaling - 1 / 255.0\n",
    "- We'll do this for both trianing and validation images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf59e56-6f90-4878-a51f-5e172e68faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f2b1d-c4f3-41f4-8ea1-dda09f10f81b",
   "metadata": {},
   "source": [
    "- You can now use this generator to load in data from a directory\n",
    "- Specify the directory path, and a siye to which each image will be resized\n",
    "    - 224x224 works well with neural networks, especially with transfer learning models (more on these in a couple of notebooks)\n",
    "- Set `class_mode='categorical'`, since we have two distinct classes\n",
    "- Set `batch_siye=64` or anything you want, it represents the number of images _shown_ to a neural network at once\n",
    "- The `seed` parameter is here so you can get the same images as I did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f5da9-155e-46ee-8898-905436433c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory='data/train/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d5ecd-36b4-4d68-b69a-53f34fb550a9",
   "metadata": {},
   "source": [
    "- There are 20030 images in the training folder divided into two classes - as reported by the loader\n",
    "- The `train_data` is basically a Python generator object\n",
    "- You can call `next()` on it to get the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5c0f4-45dc-4e62-9831-8b61d1910021",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = train_data.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0234f5-9624-4843-995d-7163db472947",
   "metadata": {},
   "source": [
    "- Each batch contains images and labels\n",
    "- Let's check the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed79b6-1e84-4abe-8997-454548a617de",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b98c9-84d4-4e5a-b0c7-b765e5a1f658",
   "metadata": {},
   "source": [
    "- So, a single batch contains 64 images, each being 224 pixels wide and tall with 3 color channels\n",
    "- There are 64 corresponding labels, each is an array of two elements - probability of an image being a cat (0) ond a dog (1)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Visualizing a single batch\n",
    "- It's always recommended to visalize your data\n",
    "- The `visualize_batch()` function, well, visualizes a single batch\n",
    "- There are 64 images in the batch, so the function plots a grid of 8x8 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb13ff6-1ab3-4c67-a89c-b30360c6cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(batch: tf.keras.preprocessing.image.DirectoryIterator):\n",
    "    n = 64\n",
    "    num_row, num_col = 8, 8\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(3 * num_col, 3 * num_row))\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = np.array(batch[0][i] * 255, dtype='uint8')\n",
    "        ax = axes[i // num_col, i % num_col]\n",
    "        ax.imshow(img)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b64b2-6fb4-4f20-bfd0-cd9c8c351af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(batch=first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bacec5-b9a4-4f19-b81c-49d6c6ac46ec",
   "metadata": {},
   "source": [
    "- Some of them look a bit weird due to change in the aspect ratio, but we should be fine\n",
    "- Let's reset the data loaders, as we called `next()` before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023a4ba-cdc1-4ba5-8a83-14636908fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory='data/train/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(\n",
    "    directory='data/validation/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1a184-5975-47b4-b62a-0c486d993bd3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Training a Convolutional model\n",
    "- Just like with regular ANN's (Dense layers), Convolutional Neural Networks boil down to experimentation\n",
    "- You can't know beforehand how many Convolutional layers you'll need, what's the ideal number of filters for each, and what's the optimal kernel size\n",
    "- Convolutional layers are usually followed by a Pooling layer, to reduce the image size\n",
    "- When finished with Convolutional layers, make sure to add a Flatten layer\n",
    "- Add Dense layers as you normally would from there\n",
    "- Keep in mind the ouput layer and the loss function\n",
    "    - Use softmax activation at output, as sigmoid only works when you have a single output node\n",
    "    - Track loss through categorical cross entropy\n",
    "- We'll train the model for 10 epochs, which is completely random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4ae8e-5597-4152-881e-0307df8059cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c3803-53f7-4094-b248-333506f2d7ce",
   "metadata": {},
   "source": [
    "- 71.23% accuracy after 10 epochs\n",
    "- Does doubling the number of filters in our single Convolutional layers make a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d79986-0090-4edf-a09e-4141e3878486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b16e1-eb5e-4c09-91cf-2ad0de77b598",
   "metadata": {},
   "source": [
    "- Maybe, but the model generally doesn't look like it's learning\n",
    "- Let's add another Convolutional layer\n",
    "    - Keep in mind: Only the first convolutional layer needs the `input_shape` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60ba3d-1340-4780-a289-c7e45510fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4afad-0e64-451a-b1b0-f1b2637bfb40",
   "metadata": {},
   "source": [
    "- Much better - we're at 75% now on the validation set\n",
    "- Let's use this model to make predictions\n",
    "\n",
    "<br>\n",
    "\n",
    "## Making predictions on new images\n",
    "- You have to apply the same preprocessing operations to the unseen images\n",
    "- I've forgot to do so many times on my job, and it results in some wierd and uncertain predictions (small difference between prediction probabilities)\n",
    "- We'll declare a `prepare_single_image()` function which resizes an image to 224x224 and rescales it to a 0-1 range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf33ef-4bf8-4bd8-8bdd-aa537a7a731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_image(img_path: str) -> np.array:\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(size=(224, 224))\n",
    "    return np.array(img) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36bc32-144a-41f7-a399-23c6883320d2",
   "metadata": {},
   "source": [
    "- Let's test it on a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f265f-96e4-4d66-939e-06b0e724f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = prepare_single_image(img_path='data/test/cat/10018.jpg')\n",
    "single_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e6dd7-f6d0-4932-ae6e-e582bad5f5a6",
   "metadata": {},
   "source": [
    "- And now let's make a single prediction\n",
    "- Note the `reshape()` function - try removing it and see what happens\n",
    "- There's an easier way, and you'll see it in a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ce1ca-2084-4e9e-a812-779c3a85830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prediction = model_3.predict(single_image.reshape(-1, 224, 224, 3))\n",
    "single_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9129f-efb1-4162-a5e8-b2ce80427243",
   "metadata": {},
   "source": [
    "- These are basically prediction probabilities\n",
    "- The model almost 100% certain that the class at index 0 is present on the image\n",
    "- Remember: 0 = cat, 1 = dog\n",
    "- You can use the argmax function to get the index where the value of an array is the highest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3b2ea-aeab-49d3-a8c0-244fffc92356",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prediction.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06211ee-46a3-4040-8d9f-edef36025741",
   "metadata": {},
   "source": [
    "- Let+s make predictions for an entire folder of images\n",
    "- First for the cats\n",
    "- The top two variables will track how many predictions were made, and how many of these were correct\n",
    "- Note the `expand_dims()` function - it's an alternative to `reshape()`\n",
    "    - You can use either\n",
    "- Prediction fails on some images probably because they are corrupted, so wrap the code inside a `try .. except` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008c764-23d8-4c00-a235-05e592ecf166",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_cat, num_correct_cat = 0, 0\n",
    "\n",
    "for img_path in pathlib.Path.cwd().joinpath('data/test/cat').iterdir():\n",
    "    try:\n",
    "        img = prepare_single_image(img_path=str(img_path))\n",
    "        pred = model_3.predict(tf.expand_dims(img, axis=0))\n",
    "        pred = pred.argmax()\n",
    "        num_total_cat += 1\n",
    "        if pred == 0:\n",
    "            num_correct_cat += 1\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c54cbe-9df1-4820-9c67-def974dcd539",
   "metadata": {},
   "source": [
    "- Total predictions made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dcc69-1cbf-4f1b-b311-959d18973448",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ebcd71-427a-444b-81e6-6f3371adbd9b",
   "metadata": {},
   "source": [
    "- Accuracy for cats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb69cb-52b2-4dde-a7cd-f4c815b87712",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_cat / num_total_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a4593-94a0-411f-9585-13412a896e3d",
   "metadata": {},
   "source": [
    "- Not too bad - let's do the same for dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257f166-3f0c-4cc6-a944-5cfa73a910ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dog, num_correct_dog = 0, 0\n",
    "\n",
    "for img_path in pathlib.Path.cwd().joinpath('data/test/dog').iterdir():\n",
    "    try:\n",
    "        img = prepare_single_image(img_path=str(img_path))\n",
    "        pred = model_3.predict(tf.expand_dims(img, axis=0))\n",
    "        pred = pred.argmax()\n",
    "        num_total_dog += 1\n",
    "        if pred == 1:\n",
    "            num_correct_dog += 1\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939e185-919c-4dd2-9b50-44abe293cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebc1d4-dde6-475e-b3f6-ee48fbc6819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_dog / num_total_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a130dd6-7aa9-49f4-9e73-0b50da851a6f",
   "metadata": {},
   "source": [
    "- Overall, we have a much more accurate model than when we were only using Dense layers\n",
    "- This is just a tip of the iceberg\n",
    "    - We haven't explored data augmentation and transfer learning\n",
    "    - You wouldn't believe how much these will increase the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
