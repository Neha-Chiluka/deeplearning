{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 3 - Getting started with Convolutional layers\n",
    "- Dataset:\n",
    "    - https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset\n",
    "- The dataset isn't deep-learning-compatible by default, here's how to preprocess it:\n",
    "- Code: https://github.com/fenago/deeplearning/blob/main/tensorflow/008_CNN_001_Working_With_Image_Data.ipynb\n",
    "    \n",
    "**Before you start**\n",
    "- I got TensorFlow errors during training because a couple of images were corrupted\n",
    "- Before continuing, please delete the following images:\n",
    "    - `data\\train\\cat\\666.jpg`\n",
    "    - `data\\train\\dog\\11702.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Normalizing image data\n",
    "- Let's load in a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open('data/train/cat/1.jpg')\n",
    "display(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And check it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's 281 pixels wide, 300 pixels tall, and has 3 color channels\n",
    "- Let's load in another image and see if the same applies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = Image.open('data/train/dog/0.jpg')\n",
    "display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second image is much larger\n",
    "- Neural network doesn't like that - it expects images (arrays) of identical sizes\n",
    "- You'll see later how to resize them on the fly\n",
    "- First, let's see how a single image looks like when represented as an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's in a range between 0 and 255 for every single color channel (red, green, and blue)\n",
    "- Neural networks prefer a range between 0 and 1\n",
    "- We can translate it to that range by dividing each element of an array by 255.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img2) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's the only argument we'll pass to the TensorFlow's ImageDataGenerator - rescaling\n",
    "- There are others available, and we'll cover them in a couple of notebooks when learning data augmentation\n",
    "\n",
    "<br>\n",
    "\n",
    "## Data loaders\n",
    "- You can use the `ImageDataGenerator` class from TensorFlow to specify how the image data will be generated\n",
    "- We'll only apply rescaling - 1 / 255.0\n",
    "- We'll do this for both trianing and validation images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can now use this generator to load in data from a directory\n",
    "- Specify the directory path, and a siye to which each image will be resized\n",
    "    - 224x224 works well with neural networks, especially with transfer learning models (more on these in a couple of notebooks)\n",
    "- Set `class_mode='categorical'`, since we have two distinct classes\n",
    "- Set `batch_siye=64` or anything you want, it represents the number of images _shown_ to a neural network at once\n",
    "- The `seed` parameter is here so you can get the same images as I did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory='data/train/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 20030 images in the training folder divided into two classes - as reported by the loader\n",
    "- The `train_data` is basically a Python generator object\n",
    "- You can call `next()` on it to get the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = train_data.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each batch contains images and labels\n",
    "- Let's check the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, a single batch contains 64 images, each being 224 pixels wide and tall with 3 color channels\n",
    "- There are 64 corresponding labels, each is an array of two elements - probability of an image being a cat (0) ond a dog (1)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Visualizing a single batch\n",
    "- It's always recommended to visalize your data\n",
    "- The `visualize_batch()` function, well, visualizes a single batch\n",
    "- There are 64 images in the batch, so the function plots a grid of 8x8 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(batch: tf.keras.preprocessing.image.DirectoryIterator):\n",
    "    n = 64\n",
    "    num_row, num_col = 8, 8\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(3 * num_col, 3 * num_row))\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = np.array(batch[0][i] * 255, dtype='uint8')\n",
    "        ax = axes[i // num_col, i % num_col]\n",
    "        ax.imshow(img)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(batch=first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some of them look a bit weird due to change in the aspect ratio, but we should be fine\n",
    "- Let's reset the data loaders, as we called `next()` before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory='data/train/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(\n",
    "    directory='data/validation/',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Training a Convolutional model\n",
    "- Just like with regular ANN's (Dense layers), Convolutional Neural Networks boil down to experimentation\n",
    "- You can't know beforehand how many Convolutional layers you'll need, what's the ideal number of filters for each, and what's the optimal kernel size\n",
    "- Convolutional layers are usually followed by a Pooling layer, to reduce the image size\n",
    "- When finished with Convolutional layers, make sure to add a Flatten layer\n",
    "- Add Dense layers as you normally would from there\n",
    "- Keep in mind the ouput layer and the loss function\n",
    "    - Use softmax activation at output, as sigmoid only works when you have a single output node\n",
    "    - Track loss through categorical cross entropy\n",
    "- We'll train the model for 10 epochs, which is completely random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 71.23% accuracy after 10 epochs\n",
    "- Does doubling the number of filters in our single Convolutional layers make a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maybe, but the model generally doesn't look like it's learning\n",
    "- Let's add another Convolutional layer\n",
    "    - Keep in mind: Only the first convolutional layer needs the `input_shape` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Much better - we're at 75% now on the validation set\n",
    "- Let's use this model to make predictions\n",
    "\n",
    "<br>\n",
    "\n",
    "## Making predictions on new images\n",
    "- You have to apply the same preprocessing operations to the unseen images\n",
    "- I've forgot to do so many times on my job, and it results in some wierd and uncertain predictions (small difference between prediction probabilities)\n",
    "- We'll declare a `prepare_single_image()` function which resizes an image to 224x224 and rescales it to a 0-1 range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_image(img_path: str) -> np.array:\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(size=(224, 224))\n",
    "    return np.array(img) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's test it on a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = prepare_single_image(img_path='data/test/cat/10018.jpg')\n",
    "single_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And now let's make a single prediction\n",
    "- Note the `reshape()` function - try removing it and see what happens\n",
    "- There's an easier way, and you'll see it in a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prediction = model_3.predict(single_image.reshape(-1, 224, 224, 3))\n",
    "single_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These are basically prediction probabilities\n",
    "- The model almost 100% certain that the class at index 0 is present on the image\n",
    "- Remember: 0 = cat, 1 = dog\n",
    "- You can use the argmax function to get the index where the value of an array is the highest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prediction.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let+s make predictions for an entire folder of images\n",
    "- First for the cats\n",
    "- The top two variables will track how many predictions were made, and how many of these were correct\n",
    "- Note the `expand_dims()` function - it's an alternative to `reshape()`\n",
    "    - You can use either\n",
    "- Prediction fails on some images probably because they are corrupted, so wrap the code inside a `try .. except` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_cat, num_correct_cat = 0, 0\n",
    "\n",
    "for img_path in pathlib.Path.cwd().joinpath('data/test/cat').iterdir():\n",
    "    try:\n",
    "        img = prepare_single_image(img_path=str(img_path))\n",
    "        pred = model_3.predict(tf.expand_dims(img, axis=0))\n",
    "        pred = pred.argmax()\n",
    "        num_total_cat += 1\n",
    "        if pred == 0:\n",
    "            num_correct_cat += 1\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total predictions made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy for cats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_cat / num_total_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not too bad - let's do the same for dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dog, num_correct_dog = 0, 0\n",
    "\n",
    "for img_path in pathlib.Path.cwd().joinpath('data/test/dog').iterdir():\n",
    "    try:\n",
    "        img = prepare_single_image(img_path=str(img_path))\n",
    "        pred = model_3.predict(tf.expand_dims(img, axis=0))\n",
    "        pred = pred.argmax()\n",
    "        num_total_dog += 1\n",
    "        if pred == 1:\n",
    "            num_correct_dog += 1\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_dog / num_total_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall, we have a much more accurate model than when we were only using Dense layers\n",
    "- This is just a tip of the iceberg\n",
    "    - We haven't explored data augmentation and transfer learning\n",
    "    - You wouldn't believe how much these will increase the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
