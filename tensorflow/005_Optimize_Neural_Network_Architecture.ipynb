{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "- https://www.kaggle.com/shelvigarg/wine-quality-dataset\n",
    "- Refer to https://github.com/fenago/deeplearning/blob/main/tensorflow/003_TensorFlow_Classification.ipynb for detailed preparation instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/winequalityN.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "df = df.dropna()\n",
    "df['is_white_wine'] = [1 if typ == 'white' else 0 for typ in df['type']]\n",
    "df['is_good_wine'] = [1 if quality >= 6 else 0 for quality in df['quality']]\n",
    "df.drop(['type', 'quality'], axis=1, inplace=True)\n",
    "\n",
    "# Train/test split\n",
    "X = df.drop('is_good_wine', axis=1)\n",
    "y = df['is_good_wine']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# How will we approach optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's declare some constants\n",
    "    - We want to optimize a network with 3 hidden layers\n",
    "    - Each hidden layer can have from 64 to 256 nodes\n",
    "    - The step size between nodes is 64\n",
    "        - So the possibilities are: 64, 128, 192, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "min_nodes_per_layer, max_nodes_per_layer = 64, 256\n",
    "node_step_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_options = list(range(\n",
    "    min_nodes_per_layer, \n",
    "    max_nodes_per_layer + 1, \n",
    "    node_step_size\n",
    "))\n",
    "node_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking them to two layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_possibilities = [node_options, node_options]\n",
    "two_layer_possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And now it's just a task of calculating all permutations between these two lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(itertools.product(*two_layer_possibilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to optimize a 3-layer-deep neural network, so we'll have a bit more possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_possibilities = [node_options] * num_layers\n",
    "layer_possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here are the permutations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_node_permutations = list(itertools.product(*layer_possibilities))\n",
    "layer_node_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll iterate over the permutations and then iterate again over the values of individual permutation to get the node count for each hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for permutation in layer_node_permutations[:2]:\n",
    "    for nodes_at_layer in permutation:\n",
    "        print(nodes_at_layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll create a new `Sequential` model at each iteration\n",
    "    - And add an `InputLayer` to it with a shape of `(12,)` (the number of columns in our dataset)\n",
    "- Then, we'll iterate over the items in a single permutation and add a `Dense` layer to the model with the current number of nodes\n",
    "- Finally, we'll add a `Dense` output layer\n",
    "- We'll also setting a name to the model so it's easier to compare them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for permutation in layer_node_permutations:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(12,)))\n",
    "    model_name = ''\n",
    "    \n",
    "    for nodes_at_layer in permutation:\n",
    "        model.add(tf.keras.layers.Dense(nodes_at_layer, activation='relu'))\n",
    "        model_name += f'dense{nodes_at_layer}_'\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model._name = model_name[:-1]\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's how a single model looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not too bad, right?\n",
    "- Let's wrap all this logic into a single function next.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Get architecture possibilities from a function\n",
    "- This one will have a lot of parameters\n",
    "- But it doesn't do anything we haven't discussed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(num_layers: int,\n",
    "               min_nodes_per_layer: int,\n",
    "               max_nodes_per_layer: int,\n",
    "               node_step_size: int,\n",
    "               input_shape: tuple,\n",
    "               hidden_layer_activation: str = 'relu',\n",
    "               num_nodes_at_output: int = 1,\n",
    "               output_layer_activation: str = 'sigmoid') -> list:\n",
    "    \n",
    "    node_options = list(range(min_nodes_per_layer, max_nodes_per_layer + 1, node_step_size))\n",
    "    layer_possibilities = [node_options] * num_layers\n",
    "    layer_node_permutations = list(itertools.product(*layer_possibilities))\n",
    "    \n",
    "    models = []\n",
    "    for permutation in layer_node_permutations:\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "        model_name = ''\n",
    "\n",
    "        for nodes_at_layer in permutation:\n",
    "            model.add(tf.keras.layers.Dense(nodes_at_layer, activation=hidden_layer_activation))\n",
    "            model_name += f'dense{nodes_at_layer}_'\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(num_nodes_at_output, activation=output_layer_activation))\n",
    "        model._name = model_name[:-1]\n",
    "        models.append(model)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = get_models(\n",
    "    num_layers=3, \n",
    "    min_nodes_per_layer=64, \n",
    "    max_nodes_per_layer=256, \n",
    "    node_step_size=64, \n",
    "    input_shape=(12,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's print the names and the count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'#Models = {len(all_models)}')\n",
    "print()\n",
    "\n",
    "for model in all_models:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we have 64 models in total\n",
    "- It will take some time to optimize\n",
    "- Let's declare another function for that\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Model optimization function\n",
    "- This one will accept the list of models, training and testing sets (both features and the target), and optionally a number of epochs and verbosity\n",
    "    - It's advised to set verbosity to 0 so you don't get overwhelmed with the console output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(models: list,\n",
    "             X_train: np.array,\n",
    "             y_train: np.array,\n",
    "             X_test: np.array,\n",
    "             y_test: np.array,\n",
    "             epochs: int = 50,\n",
    "             verbose: int = 0) -> pd.DataFrame:\n",
    "    \n",
    "    # We'll store the results here\n",
    "    results = []\n",
    "    \n",
    "    def train(model: tf.keras.Sequential) -> dict:\n",
    "        # Change this however you want\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.binary_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        preds = model.predict(X_test)\n",
    "        prediction_classes = [1 if prob > 0.5 else 0 for prob in np.ravel(preds)]\n",
    "        \n",
    "        # Return evaluation metrics on the test set\n",
    "        return {\n",
    "            'model_name': model.name,\n",
    "            'test_accuracy': accuracy_score(y_test, prediction_classes),\n",
    "            'test_precision': precision_score(y_test, prediction_classes),\n",
    "            'test_recall': recall_score(y_test, prediction_classes),\n",
    "            'test_f1': f1_score(y_test, prediction_classes)\n",
    "        }\n",
    "    \n",
    "    # Train every model and save results\n",
    "    for model in models:\n",
    "        try:\n",
    "            print(model.name, end=' ... ')\n",
    "            res = train(model=model)\n",
    "            results.append(res)\n",
    "        except Exception as e:\n",
    "            print(f'{model.name} --> {str(e)}')\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's optimize the architecture!\n",
    "- It will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_results = optimize(\n",
    "    models=models,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_results.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And there you have it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
