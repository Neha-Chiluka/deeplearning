{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset import and preparation\n",
    "- https://www.kaggle.com/shelvigarg/wine-quality-dataset\n",
    "- Refer to https://github.com/fenago/deeplearning/blob/main/tensorflow/003_TensorFlow_Classification.ipynb for detailed preparation instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/winequalityN.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "df = df.dropna()\n",
    "df['is_white_wine'] = [1 if typ == 'white' else 0 for typ in df['type']]\n",
    "df['is_good_wine'] = [1 if quality >= 6 else 0 for quality in df['quality']]\n",
    "df.drop(['type', 'quality'], axis=1, inplace=True)\n",
    "\n",
    "# Train/test split\n",
    "X = df.drop('is_good_wine', axis=1)\n",
    "y = df['is_good_wine']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Training a model which finds the optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will be the minimum and maximum values for our learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-3 * 10 ** (1 / 30), 1e-3 * 10 ** (100 / 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can pass it as a `LearningRateScheduler` callback when fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "initial_model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ]\n",
    ")\n",
    "\n",
    "initial_history = initial_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch: 1e-3 * 10 ** (epoch / 30)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy was terrible at the end - makes sense as our model had a huge learning rate\n",
    "- Let's plot loss vs. accuracy vs. learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), initial_history.history['loss'], label='Loss', lw=3)\n",
    "plt.plot(np.arange(1, 101), initial_history.history['accuracy'], label='Accuracy', lw=3)\n",
    "plt.plot(np.arange(1, 101), initial_history.history['lr'], label='Learning rate', color='#000', lw=3, linestyle='--')\n",
    "plt.title('Evaluation metrics', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend()\n",
    "plt.savefig('eval_vs_lr.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy dipped significantly around epoch 50, then flattened, and dipped once again towards the end\n",
    "- The exact opposite happened to loss\n",
    "- Let's now plot the learning rate against loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = 1e-3 * (10 ** (np.arange(100) / 30))\n",
    "plt.semilogx(learning_rates, initial_history.history['loss'], lw=3, color='#000')\n",
    "plt.title('Learning rate vs. loss', size=20)\n",
    "plt.xlabel('Learning rate', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.savefig('lr_vs_loss.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Training a model with the optimal learning rate\n",
    "- You're looking for a learning rate value that achieved minimum loss\n",
    "- Looks like 0.007 works the best for this dataset\n",
    "- Let's retrain the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimized = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_optimized.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_optimized = model_optimized.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Susipiciously high training accuracy - possible overfit\n",
    "- Let's plot loss vs. accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_optimized.history['loss'], label='Loss', lw=3)\n",
    "plt.plot(np.arange(1, 101), history_optimized.history['accuracy'], label='Accuracy', lw=3)\n",
    "plt.title('Accuracy vs. Loss per epoch', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_per_epoch.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# Model evaluation on the test set\n",
    "- Let's now make predictions, convert them to classes and print accuracy and confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_optimized.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = [1 if prob > 0.5 else 0 for prob in np.ravel(predictions)]\n",
    "print(prediction_classes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy on the test set: {accuracy_score(y_test, prediction_classes):.2f}')\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, prediction_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy on the test set increased by 3% compared to the default learning rate (0.001) used in the previous notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
