{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807431e1-4315-4fd9-93b1-a03b1d4427db",
   "metadata": {},
   "source": [
    "# CNN 2 - Training image classification models with ANNs\n",
    "\n",
    "- **Important** - Training image classifiers with plain ANNs isn't a good idea. We're training a model anyway just to see how good of a model we can get. You should never use ANNs for image classification.\n",
    "\n",
    "- Dataset: \n",
    "    - https://www.kaggle.com/pybear/cats-vs-dogs?select=PetImages\n",
    "- **Watch the previous video if you don't have the folder structure ready:**\n",
    "    - Video: https://www.youtube.com/watch?v=O7EV2BjOXus&ab_channel=BetterDataScience\n",
    "    - Article:https://towardsdatascience.com/tensorflow-for-image-classification-top-3-prerequisites-for-deep-learning-projects-34c549c89e42\n",
    "    - Code: https://github.com/fenago/deeplearning/blob/main/tensorflow/008_CNN_001_Working_With_Image_Data.ipynb\n",
    "    \n",
    "- We'll need a quite a bit of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2292d-ecd9-45d8-8070-89f9ffb4e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f65b6-4aa0-4bf0-8a49-59e0d6fe71b4",
   "metadata": {},
   "source": [
    "- Let's load in an arbitrary image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb1557-9307-491f-bd6b-8bafe08e22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img = Image.open('data/train/cat/1.jpg')\n",
    "display(src_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c142cca-2a97-474d-9e8b-6f422d5c83b6",
   "metadata": {},
   "source": [
    "- Here's the shape (width, height, color channels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391e578-491f-44d0-be39-c2120c42d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(src_img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ab8b0-234a-4fec-ae0a-485355e84ebd",
   "metadata": {},
   "source": [
    "- If flattened, it would result in this many features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a103bb5-2989-499c-b6a0-04603471168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "281 * 300 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d20ec5-d692-4528-b3ac-f7b1d34c109c",
   "metadata": {},
   "source": [
    "- We can reduce the number by a factor of 3 by grayscaling the image\n",
    "- We still know it's a cat, no matter if we lose the color info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8046d41-4a27-4885-a688-f5df5e427731",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = ImageOps.grayscale(src_img)\n",
    "display(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24004323-b753-4586-983a-aa1b51f644fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(gray_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c169c2-fbe7-4cf6-9158-31648042eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "281 * 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3908dd2-e696-40e3-9a89-4b91dd4507b1",
   "metadata": {},
   "source": [
    "- It's still a lot, so let's resize the image to something smaller\n",
    "- Let's say 96x96:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a685f0-42d5-411f-b8e5-2adb50800a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_resized_img = gray_img.resize(size=(96, 96))\n",
    "display(gray_resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19944563-1d68-48bd-8e31-0187b1ef2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(gray_resized_img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df5e05-58dd-4fd0-a702-e3dee6290e95",
   "metadata": {},
   "source": [
    "- Much less features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bc440-bc79-475a-8734-fae78f86d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "96 * 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be526c3-c5ea-4da8-8a76-e41b3296f2bb",
   "metadata": {},
   "source": [
    "- This is how you can flatten the image and store it as an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ca1f1-16f6-4a1d-aa8f-54a2d312bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(gray_resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbb763-7f45-4b7d-b478-9fd9d48fed15",
   "metadata": {},
   "source": [
    "- The values aren't in an ideal range (0-255)\n",
    "- Neural network model prefers 0-1 range\n",
    "- Let's transform it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300d09e-21e3-477c-a070-00ccdaedc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_final = np.ravel(gray_resized_img) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a5956-f6c4-429f-a0dc-93deae9495ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c176c3-9b1a-4938-bb32-d55c3b7df102",
   "metadata": {},
   "source": [
    "- Finally, let's implement all of this in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71e254-ddcc-401e-b529-fac13418d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path: str) -> np.array:\n",
    "    img = Image.open(img_path)\n",
    "    img = ImageOps.grayscale(img)\n",
    "    img = img.resize(size=(96, 96))\n",
    "    img = np.ravel(img) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820fd0f-cdbe-4173-a601-d0a39dd967ca",
   "metadata": {},
   "source": [
    "- And let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c657636-9784-41bf-8ac7-83f25d784275",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_img = process_image(img_path='data/validation/dog/10012.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24cd05-f68f-474b-af32-3d34f5c26603",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81c46b-a558-4d4a-bad6-3b276d06c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(tst_img * 255).reshape((96, 96)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9ebf4-3d0f-4b3c-8d8a-5ec7665c83e0",
   "metadata": {},
   "source": [
    "- It works as expected, so let's apply the same logic to the entire dataset next.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Process the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e4061-49bb-4704-a1c4-401882cb6b23",
   "metadata": {},
   "source": [
    "- Let's declare a function that will process all images in a given folder\n",
    "- The function returns processed images as a Pandas DataFrame\n",
    "- We'll add an additional column just so we know the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839f4e1-f884-477f-a5ff-0d1f9a72d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder: pathlib.PosixPath) -> pd.DataFrame:\n",
    "    # We'll store the images here\n",
    "    processed = []\n",
    "    \n",
    "    # For every image in the directory\n",
    "    for img in folder.iterdir():\n",
    "        # Ensure JPG\n",
    "        if img.suffix == '.jpg':\n",
    "            # Two images failed for whatever reason, so let's just ignore them\n",
    "            try:\n",
    "                processed.append(process_image(img_path=str(img)))\n",
    "            except Exception as _:\n",
    "                continue\n",
    "           \n",
    "    # Convert to pd.DataFrame\n",
    "    processed = pd.DataFrame(processed)\n",
    "    # Add a class column - dog or a cat\n",
    "    processed['class'] = folder.parts[-1]\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a51a52-239f-4fc8-9773-9fb6bdad9c3b",
   "metadata": {},
   "source": [
    "- And now let's build ourselves training, validation, and test sets\n",
    "- We'll start with the training set\n",
    "    - Process both cat and dog images\n",
    "    - Concatenate the two datasets\n",
    "    - Save them in a pickle format, just so you don't have to go through the entire process again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4723a6e-5c22-4931-9e3b-2760de264e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_cat = process_folder(folder=pathlib.Path.cwd().joinpath('data/train/cat'))\n",
    "train_dog = process_folder(folder=pathlib.Path.cwd().joinpath('data/train/dog'))\n",
    "\n",
    "train_set = pd.concat([train_cat, train_dog], axis=0)\n",
    "\n",
    "with open('train_set.pkl', 'wb') as f:\n",
    "    pickle.dump(train_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d226c-1abb-4446-a00f-b0c835c6b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5710c-513b-4f2e-a2b6-b29785846c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948ffd3-8fbe-4177-abb4-95250cdc5580",
   "metadata": {},
   "source": [
    "- Now for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559de24-d368-40b9-ade1-e97e78622596",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_cat = process_folder(folder=pathlib.Path.cwd().joinpath('data/test/cat'))\n",
    "test_dog = process_folder(folder=pathlib.Path.cwd().joinpath('data/test/dog'))\n",
    "\n",
    "test_set = pd.concat([test_cat, test_dog], axis=0)\n",
    "\n",
    "with open('test_set.pkl', 'wb') as f:\n",
    "    pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec959b-4093-4f28-a54d-24361463e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed5f84-b0e8-464b-a36f-cfe520d18f91",
   "metadata": {},
   "source": [
    "- And finally for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fd8a8-2355-41a5-9557-76d1eaaad3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_cat = process_folder(folder=pathlib.Path.cwd().joinpath('data/validation/cat'))\n",
    "valid_dog = process_folder(folder=pathlib.Path.cwd().joinpath('data/validation/dog'))\n",
    "\n",
    "valid_set = pd.concat([valid_cat, valid_dog], axis=0)\n",
    "\n",
    "with open('valid_set.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915f648-5584-459c-8930-fd83283b8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674ad82-5cf3-4de0-a92b-514a53c42158",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Additional processing\n",
    "- Datasets now contain images of cats first, followed by images of dogs\n",
    "- We want to shuffle those datasets, so a neural network  goes through the images in a random order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a39f4e-4b9f-4467-9baa-8a49996fd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = shuffle(train_set).reset_index(drop=True)\n",
    "valid_set = shuffle(valid_set).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052e6fc-1997-40ba-b006-abcc71408acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2f580-a70e-48cc-924f-61fed9306e29",
   "metadata": {},
   "source": [
    "- Separate the features from the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b7e55-f4a3-4037-865d-9090157d3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop('class', axis=1)\n",
    "y_train = train_set['class']\n",
    "\n",
    "X_valid = valid_set.drop('class', axis=1)\n",
    "y_valid = valid_set['class']\n",
    "\n",
    "X_test = test_set.drop('class', axis=1)\n",
    "y_test = test_set['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea227d6-c58b-442b-ab50-f991dc166f1a",
   "metadata": {},
   "source": [
    "- We need to factorize the target variable\n",
    "- For example, if our classes are ['cat', 'dog'], the function will convert them to integers [0, 1]\n",
    "- Then, each instance is represented as follows:\n",
    "    - Cat: [1, 0]\n",
    "    - Dog: [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bfc2a-1589-45e3-a433-b67debb9133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9f542-4f21-449d-a338-963b619c6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train.factorize()[0], num_classes=2)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid.factorize()[0], num_classes=2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test.factorize()[0], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c67969-a49e-487b-a18c-c1ad7897fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5272ac9-f48c-49b3-a1b4-641138360653",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Training the model\n",
    "- The architecture and parameters are completely random\n",
    "- Set it to whatever you want\n",
    "- We have two nodes at the output layer\n",
    "    - Represents two classes - cat and dog\n",
    "- We're using Categorical Crossentropy as a loss function because we have two categories - cat and dog\n",
    "- The model is trained for 100 epochs with a batch size of 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef06f9-7cfe-4750-8d36-8dd5fcac8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492a89d-f4aa-457b-a79d-9b2a40ec323c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inspecting performance\n",
    "- It doesn't look like the best model, as ANNs aren't the best tool for image data\n",
    "- Let's visualize training loss vs. validation loss and training accuracy vs. validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8422f52-f937-4542-a8e7-d71daf06cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8f894-2df8-4e41-8b13-bb396940acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 101), history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a3de0-929f-4f89-b058-378e9fc6c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, 101), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5dd6c-14ca-4f0c-b562-1c93829b4165",
   "metadata": {},
   "source": [
    "- The performance is terrible\n",
    "- 60% accuracy for a binary classifier is almost useless\n",
    "- Convolutions can help, and you'll see how in the following notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
