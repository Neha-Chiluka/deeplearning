{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47b18a0-f79d-4420-a39f-a454324156d9",
   "metadata": {},
   "source": [
    "# Dataset import and exploration\n",
    "- https://www.kaggle.com/shelvigarg/wine-quality-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb79fae-c37c-4c12-bdfe-cc8ba051452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/winequalityN.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689ffb8-1669-4357-8aef-6881bc454ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd172dc-747b-4d78-ae1b-e5cda329aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ac2e3-2eee-43e5-8c7c-c65efbdc67c8",
   "metadata": {},
   "source": [
    "### Drop missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199b75f-d79e-4dbe-b5c0-f9e2329eaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59a240-b30a-4a6b-84ec-c718083cf71b",
   "metadata": {},
   "source": [
    "### Encode string data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba079fe-2505-416e-8d25-1301dd003e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cf081-e757-4e4a-9a0b-621f1a5e5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_white_wine'] = [1 if typ == 'white' else 0 for typ in df['type']]\n",
    "df.drop('type', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf6432-d51f-4c58-9a8c-c7569f208ff7",
   "metadata": {},
   "source": [
    "### All data is numeric now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a7629-1daf-4c1c-b72f-0ae869666afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e5047-b462-4450-bff8-9c333f6c7203",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Convert to a binary classification problem\n",
    "- This is not a binary classification problem by default\n",
    "- We can make it one by declaring wines above some quality point good wines and rest of them bad wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6d527-53a3-47e0-9ea6-df6b70f3dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf0001-afd7-40af-8cd9-abe884f89ceb",
   "metadata": {},
   "source": [
    "- So we'll have 63.3% good wines and the rest are bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e38de-0c67-456d-b9ac-c560f7845fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['quality'] >= 6]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f8c4b-f1f2-4621-be93-90f19f6c5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_good_wine'] = [1 if quality >= 6 else 0 for quality in df['quality']]\n",
    "df.drop('quality', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297cfe8-e1e4-40bc-9000-0bd669297452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_good_wine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bc6c4-af3d-46ef-bdf6-f23f0e5358a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813fdf1-3903-4cc9-8398-f3fef2e9ec88",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf1737-b194-4944-8030-85dc727a9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('is_good_wine', axis=1)\n",
    "y = df['is_good_wine']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77266c-ef78-43b0-8dec-c78629bc669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92439aaa-3eee-4905-8fd3-f4be2ddda76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd392f14-7737-4c5f-a910-a22216ff2dc7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Data scaling\n",
    "- Input features aren't on the same scale, so we'll fix it quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635952f-0d8c-4e3a-976f-0ea422dff3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d200c89-9261-4acf-b159-2041c734f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3a432-4fb6-4b41-8842-66f570fde83a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6fa8d-4841-483c-b628-9cb9d96b08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01feaafd-15f9-4ca2-b01c-2cfe0533c5d3",
   "metadata": {},
   "source": [
    "- This is a completely random neural network architecture\n",
    "- Use `sigmoid` as the activation function in the last layer when working with binary classification problems\n",
    "- Use `binary_crossentropy` as a loss function when working with binary classification problems\n",
    "- We'll track accuracy, precision, and recall and train for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41278f-bd2f-40e0-b630-42239351ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.03),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ca6f0-716a-43e1-86a6-62650708dd64",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Model performance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ffcfc3-5c07-411b-8add-5e0832d7b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3587b-9851-4cff-8344-017ac5e588a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history.history['loss'], label='Loss')\n",
    "plt.plot(np.arange(1, 101), history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(np.arange(1, 101), history.history['precision'], label='Precision')\n",
    "plt.plot(np.arange(1, 101), history.history['recall'], label='Recall')\n",
    "plt.title('Evaluation metrics', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c005cef-8865-41bb-abdd-82b7a166d24e",
   "metadata": {},
   "source": [
    "- You could keep training the model, as accuracy, precision, and recall seem to grow slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab69ad0-2259-47b7-8bc9-dbc7476a56c3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01211471-77a6-4142-a05e-de7a8b879f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81dccb-6028-474d-b713-38a95a073f9b",
   "metadata": {},
   "source": [
    "- These are probabilities - here's how to convert them to classes (threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677aea5-dc74-4a2d-8188-c2bd0a55a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = [1 if prob > 0.5 else 0 for prob in np.ravel(predictions)]\n",
    "print(prediction_classes[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccef621-132a-47c1-bb96-65ea416e6261",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a0d83-64b0-4053-bd6a-deff0c3ddc43",
   "metadata": {},
   "source": [
    "- Evaluation on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739bced-2dd0-49bb-9af5-72779ea911b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test_scaled, y_test)\n",
    "loss, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a425e-b177-435d-b47c-670ef16a8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, prediction_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d3cfb-7d42-47d5-a1c8-dd86eb333eca",
   "metadata": {},
   "source": [
    "- 383 True Negatives, 597 True positives, 214 False negatives, 99 False positives\n",
    "- Further evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b0afb-a242-4ea3-aef7-7105f8557bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f'Accuracy:  {accuracy_score(y_test, prediction_classes):.2f}')\n",
    "print(f'Precision: {precision_score(y_test, prediction_classes):.2f}')\n",
    "print(f'Recall:    {recall_score(y_test, prediction_classes):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
