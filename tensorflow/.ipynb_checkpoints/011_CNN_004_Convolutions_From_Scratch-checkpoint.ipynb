{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 4 - Convolutions from scratch\n",
    "- Dataset:\n",
    "    - https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset\n",
    "- The dataset isn't deep-learning-compatible by default, here's how to preprocess it:\n",
    "- Code: https://github.com/fenago/deeplearning/blob/main/tensorflow/008_CNN_001_Working_With_Image_Data.ipynb\n",
    "    \n",
    "- Today we'll implement convolutions from scratch in pure Numpy\n",
    "- A convolution boils down to repetitve matrix element-wise multiplication and summation, which should be easy to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's declare two functions for plotting images\n",
    "- The first one plots a single image\n",
    "- The second one plots two images side by side (1 row, 2 columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img: np.array):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    \n",
    "def plot_two_images(img1: np.array, img2: np.array):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[1].imshow(img2, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And now let's load in the image\n",
    "    - We'll apply grayscaling and resizing to 224x224\n",
    "    - Without grayscaling you'd have to apply convolution to each of the three color channels individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/train/cat/1.jpg')\n",
    "img = ImageOps.grayscale(img)\n",
    "img = img.resize(size=(224, 224))\n",
    "plot_image(img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Declare filters for convolutions\n",
    "- The task of a convolutional layer is to find N filters (kernels) that best extract features from the dataset\n",
    "- Did you know there are known filters for doing various image operations?\n",
    "    - We'll declare ones for sharpening, blurring, and outlining\n",
    "    - Explore the rest here: https://setosa.io/ev/image-kernels/\n",
    "- These are just 3x3 matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "blur = np.array([\n",
    "    [0.0625, 0.125, 0.0625],\n",
    "    [0.125,  0.25,  0.125],\n",
    "    [0.0625, 0.125, 0.0625]\n",
    "])\n",
    "\n",
    "outline = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Implement convolution from scratch\n",
    "- We'll declare a helper function to make our lives easier\n",
    "- It will calculate the target image size\n",
    "- Sliding a 3x3 filter over an image means we'll lose a single pixel on all ends\n",
    "    - You can address this with padding, but more on that later\n",
    "    - For example, sliding a 3x3 filter over a 224x224 images results in a 222x222 image\n",
    "    - Sliding a 5x5 filter over a 224x224 images results in a 220x220 image\n",
    "- Let's write the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_size(img_size: int, kernel_size: int) -> int:\n",
    "    num_pixels = 0\n",
    "    \n",
    "    # From 0 up to img size (if img size = 224, then up to 223)\n",
    "    for i in range(img_size):\n",
    "        # Add the kernel size (let's say 3) to the current i\n",
    "        added = i + kernel_size\n",
    "        # It must be lower than the image size\n",
    "        if added <= img_size:\n",
    "            # Increment if so\n",
    "            num_pixels += 1\n",
    "            \n",
    "    return num_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Works as advertised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=224, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=224, kernel_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Here's what convolution boils down to:\n",
    "1. Let's extract the first 3x3 matrix from our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = np.array(img)[0:0+3, 0:0+3]\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do an element-wise multiplication between the image and the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(subset, sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sum the elements in the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.multiply(subset, sharpen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And that's it!\n",
    "- We can now apply this logic to the entire image\n",
    "- The trickiest part is keeping track of the current N x N matrix\n",
    "- You need to iterate over all rows and all columns in the image and than subset the image from there and apply the convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(img: np.array, kernel: np.array) -> np.array:\n",
    "    # Assuming a rectangular image\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape[0],\n",
    "        kernel_size=kernel.shape[0]\n",
    "    )\n",
    "    # To simplify things\n",
    "    k = kernel.shape[0]\n",
    "    \n",
    "    # 2D array of zeros\n",
    "    convolved_img = np.zeros(shape=(tgt_size, tgt_size))\n",
    "    \n",
    "    # Iterate over the rows\n",
    "    for i in range(tgt_size):\n",
    "        # Iterate over the columns\n",
    "        for j in range(tgt_size):\n",
    "            # img[i, j] = individual pixel value\n",
    "            # Get the current matrix\n",
    "            mat = img[i:i+k, j:j+k]\n",
    "            \n",
    "            # Apply the convolution - element-wise multiplication and summation of the result\n",
    "            # Store the result to i-th row and j-th column of our convolved_img array\n",
    "            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))\n",
    "            \n",
    "    return convolved_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's test it\n",
    "- Sharpening filter first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sharpened = convolve(img=np.array(img), kernel=sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's how the image looks like in matrix format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sharpened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let/s visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The colors are a bit off since values in the matrix don't range between 0 and 255\n",
    "- It's not a problem, but we can \"fix\" it by replacing all negative values with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_to_zero(img: np.array) -> np.array:\n",
    "    img = img.copy()\n",
    "    img[img < 0] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And plot it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_sharpened)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see that the image definitely looks sharper, no arguing there\n",
    "- Let's blur the image next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blurred = convolve(img=np.array(img), kernel=blur)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_blurred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The blurring filter matrix doesn't have negative values, so the coloring is identical\n",
    "- You can clearly see how the image was blurred\n",
    "- Finally, let's apply the outline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_outlined = convolve(img=np.array(img), kernel=outline)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_outlined\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It suffers from the same coloring problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_outlined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amazing!\n",
    "- All convolved images are of shape 222x222\n",
    "- What if you want to keep the original size of 224x224?\n",
    "- That's where padding comes into play\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Implement convolutions with padding from scratch\n",
    "- TensorFlow's `Conv2D` layer lets you specify either `valid` or `same` for the `padding` parameter\n",
    "- The first one is default, which means no padding is added to the images (what we implemented above)\n",
    "- The second one will add padding depending on the kernel size, so the source and convolved images are of the same shape\n",
    "- Padding is essentially just a \"black\" border around the image\n",
    "    - It's black because typically zeros are added, and zeros represent the color black\n",
    "    - The black borders don't have an impact on the calculations, since they're zero, and a convolution operation multiplies elements of an image with the elements of a filter. Anything multiplied with a zero is a zero\n",
    "- First, let's declare a helper function that calculates how \"thick\" of a border we need to add to the image\n",
    "    - The bigger the kernel size, the thicker the border\n",
    "    - All sides of the image will have the exact same border\n",
    "    - It's just an integer division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_width_per_side(kernel_size: int) -> int:\n",
    "    # Simple integer division\n",
    "    return kernel_size // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, 3x3 kernel means 3 // 2 which is 1\n",
    "- Add 1 pixel to each side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_3x3 = get_padding_width_per_side(kernel_size=3)\n",
    "pad_3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 // 2 = 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_5x5 = get_padding_width_per_side(kernel_size=5)\n",
    "pad_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's declare yet another helper function\n",
    "- It's task is to add a padding to the image\n",
    "- First, the function declares a matrix of zeros with a shape of (image.shape + padding * 2)\n",
    "    - We multiply the padding with 2 because we need it on all sides\n",
    "- Then we index the matrix so the padding is ignored and change the zeros with the actual image values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_image(img: np.array, padding_width: int) -> np.array:\n",
    "    # Array of zeros of shape (img + padding_width)\n",
    "    img_with_padding = np.zeros(shape=(\n",
    "        img.shape[0] + padding_width * 2,  # Multiply with two because we need padding on all sides\n",
    "        img.shape[1] + padding_width * 2\n",
    "    ))\n",
    "    \n",
    "    # Change the inner elements\n",
    "    # For example, if img.shape = (224, 224), and img_with_padding.shape = (226, 226)\n",
    "    # keep the pixel wide padding on all sides, but change the other values to be the same as img\n",
    "    img_with_padding[padding_width:-padding_width, padding_width:-padding_width] = img\n",
    "    \n",
    "    return img_with_padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's test it by adding a padding to the image for 3x3 filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_3x3 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_3x3\n",
    ")\n",
    "\n",
    "print(img_with_padding_3x3.shape)\n",
    "plot_image(img_with_padding_3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It adds a 1 pixel-wide border to the image and makes it 226x226 in size\n",
    "- Here's how the matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see the original image surrounded with zeros - that's just what we wanted\n",
    "- Let's see if the same is true for the 5x5 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_5x5 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_5x5\n",
    ")\n",
    "\n",
    "print(img_with_padding_5x5.shape)\n",
    "plot_image(img_with_padding_5x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can now visually see the black border, but still let's verify it's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Everything looks good\n",
    "- Let's apply a convolution operation to our 226x226 image (1 pixel-wide border):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_padded_3x3_sharpened = convolve(img=img_with_padding_3x3, kernel=sharpen)\n",
    "img_padded_3x3_sharpened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result is an 224x224 image, which is the same as the original one!\n",
    "- Let's plot them side by side to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_padded_3x3_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And that's how convolutions and padding work\n",
    "- TensorFlow's Conv2D layer is here to find the optimal filter matrices, but once it does, this is essentially what happens.\n",
    "- The next notebook will cover pooling from scratch, so stay tuned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
