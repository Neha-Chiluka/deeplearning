{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced47c0a-59ca-46e1-8edf-414ae641859b",
   "metadata": {},
   "source": [
    "# CNN 4 - Convolutions from scratch\n",
    "- Dataset:\n",
    "    - https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset\n",
    "- The dataset isn't deep-learning-compatible by default, here's how to preprocess it:\n",
    "    - Video: https://www.youtube.com/watch?v=O7EV2BjOXus&ab_channel=BetterDataScience\n",
    "    - Article: https://towardsdatascience.com/tensorflow-for-image-classification-top-3-prerequisites-for-deep-learning-projects-34c549c89e42\n",
    "    - Code: https://github.com/better-data-science/TensorFlow/blob/main/008_CNN_001_Working_With_Image_Data.ipynb\n",
    "    \n",
    "- Today we'll implement convolutions from scratch in pure Numpy\n",
    "- A convolution boils down to repetitve matrix element-wise multiplication and summation, which should be easy to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d6324-64a0-4041-9de1-72a073178f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195fe4f-790f-4c46-8ab4-99ee0072d37e",
   "metadata": {},
   "source": [
    "- Let's declare two functions for plotting images\n",
    "- The first one plots a single image\n",
    "- The second one plots two images side by side (1 row, 2 columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e09c17-6e19-4aa2-b8e5-ad075b202b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img: np.array):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    \n",
    "def plot_two_images(img1: np.array, img2: np.array):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[1].imshow(img2, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629e7d2-96ce-4216-a087-f82b90a14d65",
   "metadata": {},
   "source": [
    "- And now let's load in the image\n",
    "    - We'll apply grayscaling and resizing to 224x224\n",
    "    - Without grayscaling you'd have to apply convolution to each of the three color channels individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f64da8-0d55-4a2e-a054-4055e2709ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/train/cat/1.jpg')\n",
    "img = ImageOps.grayscale(img)\n",
    "img = img.resize(size=(224, 224))\n",
    "plot_image(img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b992ad-fee9-496e-b548-8efdeae831ef",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Declare filters for convolutions\n",
    "- The task of a convolutional layer is to find N filters (kernels) that best extract features from the dataset\n",
    "- Did you know there are known filters for doing various image operations?\n",
    "    - We'll declare ones for sharpening, blurring, and outlining\n",
    "    - Explore the rest here: https://setosa.io/ev/image-kernels/\n",
    "- These are just 3x3 matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adff204-1285-43fe-adb5-0618dd1947fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "blur = np.array([\n",
    "    [0.0625, 0.125, 0.0625],\n",
    "    [0.125,  0.25,  0.125],\n",
    "    [0.0625, 0.125, 0.0625]\n",
    "])\n",
    "\n",
    "outline = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29c008-4ff2-41e3-ae2d-afd1b1639974",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Implement convolution from scratch\n",
    "- We'll declare a helper function to make our lives easier\n",
    "- It will calculate the target image size\n",
    "- Sliding a 3x3 filter over an image means we'll lose a single pixel on all ends\n",
    "    - You can address this with padding, but more on that later\n",
    "    - For example, sliding a 3x3 filter over a 224x224 images results in a 222x222 image\n",
    "    - Sliding a 5x5 filter over a 224x224 images results in a 220x220 image\n",
    "- Let's write the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86789a2d-e473-457e-b485-7ab17f2f5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_size(img_size: int, kernel_size: int) -> int:\n",
    "    num_pixels = 0\n",
    "    \n",
    "    # From 0 up to img size (if img size = 224, then up to 223)\n",
    "    for i in range(img_size):\n",
    "        # Add the kernel size (let's say 3) to the current i\n",
    "        added = i + kernel_size\n",
    "        # It must be lower than the image size\n",
    "        if added <= img_size:\n",
    "            # Increment if so\n",
    "            num_pixels += 1\n",
    "            \n",
    "    return num_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cccb3-b2a6-4577-9152-e44d8210afda",
   "metadata": {},
   "source": [
    "- Works as advertised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cd518-e6d8-49a5-85e7-51d367b232bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=224, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5068c-0027-47b9-9ef1-01c01fc7de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=224, kernel_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df021c-14a4-4c0d-81bf-53bf261ab101",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Here's what convolution boils down to:\n",
    "1. Let's extract the first 3x3 matrix from our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7bf3e-070c-49d3-a320-2340a37c684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = np.array(img)[0:0+3, 0:0+3]\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162f0b2-bd32-40fe-8ca3-27155af1a76b",
   "metadata": {},
   "source": [
    "2. Do an element-wise multiplication between the image and the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef623bd-41d1-4c2f-83a9-654da2b073cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(subset, sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28ab2c-cb7f-4144-8c6a-f4bf84450040",
   "metadata": {},
   "source": [
    "3. Sum the elements in the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7585b60-aacc-427b-aa92-f41ed5168145",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.multiply(subset, sharpen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92225d0f-7086-43ea-ae4c-23b061619e24",
   "metadata": {},
   "source": [
    "- And that's it!\n",
    "- We can now apply this logic to the entire image\n",
    "- The trickiest part is keeping track of the current N x N matrix\n",
    "- You need to iterate over all rows and all columns in the image and than subset the image from there and apply the convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23afd733-dc4f-44a5-b80a-80d1bf430007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(img: np.array, kernel: np.array) -> np.array:\n",
    "    # Assuming a rectangular image\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape[0],\n",
    "        kernel_size=kernel.shape[0]\n",
    "    )\n",
    "    # To simplify things\n",
    "    k = kernel.shape[0]\n",
    "    \n",
    "    # 2D array of zeros\n",
    "    convolved_img = np.zeros(shape=(tgt_size, tgt_size))\n",
    "    \n",
    "    # Iterate over the rows\n",
    "    for i in range(tgt_size):\n",
    "        # Iterate over the columns\n",
    "        for j in range(tgt_size):\n",
    "            # img[i, j] = individual pixel value\n",
    "            # Get the current matrix\n",
    "            mat = img[i:i+k, j:j+k]\n",
    "            \n",
    "            # Apply the convolution - element-wise multiplication and summation of the result\n",
    "            # Store the result to i-th row and j-th column of our convolved_img array\n",
    "            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))\n",
    "            \n",
    "    return convolved_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9848358-1349-42dd-919d-dc3288207ffd",
   "metadata": {},
   "source": [
    "- Let's test it\n",
    "- Sharpening filter first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf18bc1-99cd-4444-a82f-194ca9c89bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sharpened = convolve(img=np.array(img), kernel=sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac08ff4-ecc7-4e75-bed7-d8a1d83a89e3",
   "metadata": {},
   "source": [
    "- Here's how the image looks like in matrix format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599678bb-316d-4fc5-89f0-f14850d26067",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sharpened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a4f30-21b6-4838-8f25-1684ad1ac2bb",
   "metadata": {},
   "source": [
    "- Let/s visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfc65f-c483-4df7-8b94-276f128d0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32eaec-a29d-4c73-9d49-3760f095aa35",
   "metadata": {},
   "source": [
    "- The colors are a bit off since values in the matrix don't range between 0 and 255\n",
    "- It's not a problem, but we can \"fix\" it by replacing all negative values with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759809f-8e21-4a92-9b33-71991a245907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_to_zero(img: np.array) -> np.array:\n",
    "    img = img.copy()\n",
    "    img[img < 0] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef45e0-7730-4475-b88d-3e7206e56f2a",
   "metadata": {},
   "source": [
    "- And plot it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc365e25-3603-426d-ab51-8d62f6c8fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_sharpened)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f62e8-0283-4094-a1e1-810077a9274f",
   "metadata": {},
   "source": [
    "- You can see that the image definitely looks sharper, no arguing there\n",
    "- Let's blur the image next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51594cf-0367-4b51-ab7d-fc5997110220",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blurred = convolve(img=np.array(img), kernel=blur)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_blurred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacf263-5ebc-43b4-bd19-d5a02884d0ae",
   "metadata": {},
   "source": [
    "- The blurring filter matrix doesn't have negative values, so the coloring is identical\n",
    "- You can clearly see how the image was blurred\n",
    "- Finally, let's apply the outline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f7af8-d82b-4c7a-8ebe-5c4e6b47f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_outlined = convolve(img=np.array(img), kernel=outline)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_outlined\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cdd63-ee09-4286-bac9-78b3cf2a5e38",
   "metadata": {},
   "source": [
    "- It suffers from the same coloring problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756f768-a3a5-4495-8358-5edc584a5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_outlined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1285a-c9b8-4760-9aaa-d2f54005408b",
   "metadata": {},
   "source": [
    "- Amazing!\n",
    "- All convolved images are of shape 222x222\n",
    "- What if you want to keep the original size of 224x224?\n",
    "- That's where padding comes into play\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Implement convolutions with padding from scratch\n",
    "- TensorFlow's `Conv2D` layer lets you specify either `valid` or `same` for the `padding` parameter\n",
    "- The first one is default, which means no padding is added to the images (what we implemented above)\n",
    "- The second one will add padding depending on the kernel size, so the source and convolved images are of the same shape\n",
    "- Padding is essentially just a \"black\" border around the image\n",
    "    - It's black because typically zeros are added, and zeros represent the color black\n",
    "    - The black borders don't have an impact on the calculations, since they're zero, and a convolution operation multiplies elements of an image with the elements of a filter. Anything multiplied with a zero is a zero\n",
    "- First, let's declare a helper function that calculates how \"thick\" of a border we need to add to the image\n",
    "    - The bigger the kernel size, the thicker the border\n",
    "    - All sides of the image will have the exact same border\n",
    "    - It's just an integer division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44684169-4204-4057-bb1b-1781999b4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_width_per_side(kernel_size: int) -> int:\n",
    "    # Simple integer division\n",
    "    return kernel_size // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff592d8-5092-41cb-bef2-fdab7fc91ef7",
   "metadata": {},
   "source": [
    "- For example, 3x3 kernel means 3 // 2 which is 1\n",
    "- Add 1 pixel to each side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80cdc4-b164-4d05-b712-ceaca7234b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_3x3 = get_padding_width_per_side(kernel_size=3)\n",
    "pad_3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069ad58-34b6-444c-9c61-afd6f974b5d2",
   "metadata": {},
   "source": [
    "- 5 // 2 = 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f493e2-1b83-4312-8570-21dbca7ffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_5x5 = get_padding_width_per_side(kernel_size=5)\n",
    "pad_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db35df4-0036-482b-b70a-f693bb6905ca",
   "metadata": {},
   "source": [
    "- Let's declare yet another helper function\n",
    "- It's task is to add a padding to the image\n",
    "- First, the function declares a matrix of zeros with a shape of (image.shape + padding * 2)\n",
    "    - We multiply the padding with 2 because we need it on all sides\n",
    "- Then we index the matrix so the padding is ignored and change the zeros with the actual image values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b303388-17f8-4a16-a49a-0539c5bc87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_image(img: np.array, padding_width: int) -> np.array:\n",
    "    # Array of zeros of shape (img + padding_width)\n",
    "    img_with_padding = np.zeros(shape=(\n",
    "        img.shape[0] + padding_width * 2,  # Multiply with two because we need padding on all sides\n",
    "        img.shape[1] + padding_width * 2\n",
    "    ))\n",
    "    \n",
    "    # Change the inner elements\n",
    "    # For example, if img.shape = (224, 224), and img_with_padding.shape = (226, 226)\n",
    "    # keep the pixel wide padding on all sides, but change the other values to be the same as img\n",
    "    img_with_padding[padding_width:-padding_width, padding_width:-padding_width] = img\n",
    "    \n",
    "    return img_with_padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fb3a3-90b9-40a8-9bf0-950e83aef9ac",
   "metadata": {},
   "source": [
    "- Let's test it by adding a padding to the image for 3x3 filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a6559-dbae-407f-b79f-51c2768ee4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_3x3 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_3x3\n",
    ")\n",
    "\n",
    "print(img_with_padding_3x3.shape)\n",
    "plot_image(img_with_padding_3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92388fb3-ef70-46e7-8465-95bff4b49ed5",
   "metadata": {},
   "source": [
    "- It adds a 1 pixel-wide border to the image and makes it 226x226 in size\n",
    "- Here's how the matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039121fd-1e37-4211-a221-47a4fb577603",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39757052-a1d9-4f95-ac3a-b0fe73f73887",
   "metadata": {},
   "source": [
    "- You can see the original image surrounded with zeros - that's just what we wanted\n",
    "- Let's see if the same is true for the 5x5 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151f10f-2445-456f-aa83-5115d4c3a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_5x5 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_5x5\n",
    ")\n",
    "\n",
    "print(img_with_padding_5x5.shape)\n",
    "plot_image(img_with_padding_5x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cd0c5-997a-4f3b-b514-93b016620b76",
   "metadata": {},
   "source": [
    "- You can now visually see the black border, but still let's verify it's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46730810-5823-4743-b709-c0ad970fb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_padding_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e98dc-1be4-41ec-a7ed-55adff523c7e",
   "metadata": {},
   "source": [
    "- Everything looks good\n",
    "- Let's apply a convolution operation to our 226x226 image (1 pixel-wide border):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994e1c5-8405-4b80-94f7-a74278e17f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_padded_3x3_sharpened = convolve(img=img_with_padding_3x3, kernel=sharpen)\n",
    "img_padded_3x3_sharpened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07179a9-6b70-440b-81e6-e29b895584ad",
   "metadata": {},
   "source": [
    "- The result is an 224x224 image, which is the same as the original one!\n",
    "- Let's plot them side by side to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82631a-8615-4f4d-b3d0-6d027b3761a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_padded_3x3_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb390d09-9f25-41f8-a703-372fc6aa9066",
   "metadata": {},
   "source": [
    "- And that's how convolutions and padding work\n",
    "- TensorFlow's Conv2D layer is here to find the optimal filter matrices, but once it does, this is essentially what happens.\n",
    "- The next notebook will cover pooling from scratch, so stay tuned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
